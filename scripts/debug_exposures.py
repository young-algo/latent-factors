#!/usr/bin/env python3
"""
Factor Exposures Debugging Tool: Data Quality Analysis and Validation
=====================================================================

This debugging script provides detailed analysis of factor exposure matrices
generated by the FactorResearchSystem, focusing on data quality issues,
missing values, and numerical stability problems that can affect factor
discovery and model fitting.

Purpose
-------
- **Data Quality Assessment**: Identify NaN, infinite, and missing values
- **Exposure Matrix Analysis**: Validate fundamental exposure calculations
- **Debugging Support**: Quick diagnostic tool for factor model issues
- **Validation Framework**: Ensure data quality before factor fitting

Key Features
-----------
- **Quick Setup**: Uses minimal ticker universe for fast debugging
- **Comprehensive Checks**: NaN detection, infinite value analysis, shape validation
- **Date-by-Date Analysis**: Examines exposure quality over time
- **Column-Level Diagnostics**: Identifies problematic fundamental metrics
- **Error Isolation**: Helps isolate data quality issues to specific metrics/dates

Debugging Workflow
-----------------
1. **Initialize System**: Create FactorResearchSystem with small universe
2. **Load Price Data**: Validate basic price data availability
3. **Build Exposures**: Generate fundamental exposure matrices
4. **Quality Analysis**: Check for NaN, infinite, and missing values
5. **Detailed Diagnostics**: Column-by-column analysis of data issues

Output Information
-----------------
- Price data shape and sample values
- Exposure matrix dimensions for each date
- NaN and infinite value counts
- Column-level missing data analysis
- Specific problematic metrics identification

Usage
-----
```bash
# Set environment variable
export ALPHAVANTAGE_API_KEY="your_api_key"

# Run debugging analysis
python debug_exposures.py

# Expected output:
# Price data shape: (1247, 3)
# Price data head:
#             AAPL    MSFT    GOOGL
# 2020-04-01  240.91  157.71  1120.84
# ...
# Date: 2020-04-02
# Exposures shape: (3, 8)
# NaN count: 2
# Inf count: 0
# Columns with NaNs:
#   profitMargin: 1 NaNs
#   beta: 1 NaNs
```

Common Issues Identified
-----------------------
- **Missing Fundamental Data**: Some tickers lack recent fundamental metrics
- **Infinite Values**: Division by zero in ratio calculations  
- **Stale Data**: Fundamental data not updated for recent periods
- **Calculation Errors**: Numerical instability in derived metrics

Dependencies
-----------
- **Core**: sys, os, pandas, numpy
- **Project**: research.FactorResearchSystem from src/
- **Environment**: ALPHAVANTAGE_API_KEY environment variable
- **Database**: Compatible SQLite cache file

Integration Points
-----------------
- **Tests**: FactorResearchSystem._build_exposures() method
- **Debugs**: Fundamental factor construction pipeline
- **Validates**: Data quality before factor discovery
- **Informs**: Model configuration and data cleaning needs

Notes
-----
This script uses a minimal ticker universe (AAPL, MSFT, GOOGL) for fast
debugging. The same analysis approach can be applied to larger universes
when needed. It's designed to quickly identify data quality issues that
could affect factor model performance.
"""

import sys
sys.path.append('src')
from research import FactorResearchSystem
import pandas as pd
import numpy as np

import os
API_KEY = os.getenv("ALPHAVANTAGE_API_KEY")
if not API_KEY:
    raise ValueError("ALPHAVANTAGE_API_KEY environment variable is required")
db_path = "/Users/kevinturner/Documents/Code/equity-factors/src/av_cache.db"

# Initialize with just a few tickers to debug quickly
frs = FactorResearchSystem(API_KEY, universe=["AAPL", "MSFT", "GOOGL"], 
                          factor_method="fundamental", db_path=db_path)

# Load price data
px = frs.get_prices(["AAPL", "MSFT", "GOOGL"])
print(f"Price data shape: {px.shape}")
print(f"Price data head:\n{px.head()}")

# Build exposures for debugging
expos_dict = frs._build_exposures(px)

# Check the first few exposures
first_dates = list(expos_dict.keys())[:3]
for dt in first_dates:
    x = expos_dict[dt]
    print(f"\nDate: {dt}")
    print(f"Exposures shape: {x.shape}")
    print(f"NaN count: {x.isnull().sum().sum()}")
    print(f"Inf count: {np.isinf(x.select_dtypes(include=[np.number])).sum().sum()}")
    if x.isnull().sum().sum() > 0:
        print("Columns with NaNs:")
        for col in x.columns:
            nan_count = x[col].isnull().sum()
            if nan_count > 0:
                print(f"  {col}: {nan_count} NaNs")